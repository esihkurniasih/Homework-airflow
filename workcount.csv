from pyspark.sql import SparkSession
from pyspark.sql.functions import explode, split, col

# Inisialisasi SparkSession
spark = SparkSession.builder.appName("WordCount").getOrCreate()

# Baca file teks
text_file = spark.read.text("path/to/book.txt")

# Proses data untuk menghitung kata
words = text_file.select(explode(split(text_file.value, "\\s+")).alias("word"))
word_counts = words.groupBy("word").count().orderBy(col("count").desc())

# Simpan hasilnya
word_counts.write.csv("path/to/output/wordcount")

# Hentikan SparkSession
spark.stop()
